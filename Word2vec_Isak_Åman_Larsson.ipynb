{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2vec Isak Åman Larsson",
      "provenance": [],
      "authorship_tag": "ABX9TyN6uuVi48Ms75Sr8benBTIC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsakLarsson/Deep-Learning-labs/blob/main/Word2vec_Isak_%C3%85man_Larsson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMLNUeDujYMh"
      },
      "source": [
        "#Isak Åman Larsson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMs8TpgRjbF0"
      },
      "source": [
        "##Importera nyttiga saker till miljön"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC15cNVxdURt"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.utils import to_categorical\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CicuB3yYkWsG"
      },
      "source": [
        "Använder mig även här av IMDB datasetet, när man importerar det via tensorflows egna load_data så kommer det färdig encodat. Alltså måste jag konvertera tillbaks det för att använda word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zfGDGCrkWDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ff00af7-b06b-4211-b060-10bf6635205c"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "# ta bara top X orden, denna kan lekas med och tas in i load_data, annars tas allt med\n",
        "NUM_WORDS=1000\n",
        "INDEX_FROM=3   # från vilket index orden börjar indexeras\n",
        "\n",
        "train,test = imdb.load_data(\n",
        "    #num_words=NUM_WORDS,\n",
        "    index_from=INDEX_FROM\n",
        "    )\n",
        "train_x,train_y = train\n",
        "test_x,test_y = test\n",
        "\n",
        "word_to_id = imdb.get_word_index()\n",
        "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START>\"] = 1\n",
        "word_to_id[\"<OOV>\"] = 2\n",
        "word_to_id[\"<UNUSED>\"] = 3\n",
        "\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}\n",
        "\n",
        "#konvertera från IDn till ord och lägg till i en lista\n",
        "review_lines= list()\n",
        "for review in train_x:\n",
        "  word_list = []\n",
        "  for wordID in review:\n",
        "    word_list.append(id_to_word[wordID])\n",
        "\n",
        "  review_lines.append(word_list)\n",
        "\n",
        "# Printa en godtycklig review\n",
        "print(review_lines[2])"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<START>', 'this', 'has', 'to', 'be', 'one', 'of', 'the', 'worst', 'films', 'of', 'the', '1990s', 'when', 'my', 'friends', 'i', 'were', 'watching', 'this', 'film', 'being', 'the', 'target', 'audience', 'it', 'was', 'aimed', 'at', 'we', 'just', 'sat', 'watched', 'the', 'first', 'half', 'an', 'hour', 'with', 'our', 'jaws', 'touching', 'the', 'floor', 'at', 'how', 'bad', 'it', 'really', 'was', 'the', 'rest', 'of', 'the', 'time', 'everyone', 'else', 'in', 'the', 'theatre', 'just', 'started', 'talking', 'to', 'each', 'other', 'leaving', 'or', 'generally', 'crying', 'into', 'their', 'popcorn', 'that', 'they', 'actually', 'paid', 'money', 'they', 'had', 'earnt', 'working', 'to', 'watch', 'this', 'feeble', 'excuse', 'for', 'a', 'film', 'it', 'must', 'have', 'looked', 'like', 'a', 'great', 'idea', 'on', 'paper', 'but', 'on', 'film', 'it', 'looks', 'like', 'no', 'one', 'in', 'the', 'film', 'has', 'a', 'clue', 'what', 'is', 'going', 'on', 'crap', 'acting', 'crap', 'costumes', 'i', \"can't\", 'get', 'across', 'how', 'embarrasing', 'this', 'is', 'to', 'watch', 'save', 'yourself', 'an', 'hour', 'a', 'bit', 'of', 'your', 'life']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsKqbeBzuSbr"
      },
      "source": [
        "Denna review va inte speciellt positiv..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYYS7s8a2AE5"
      },
      "source": [
        "##Importera Word2Vec modellen och kör reviewsen genom den"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkBUkhE4rAiN",
        "outputId": "98fc95bd-fa14-43a7-e5e0-8ffac0678f82"
      },
      "source": [
        "import gensim\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "WINDOW_SIZE = 5\n",
        "\n",
        "model = gensim.models.Word2Vec(sentences=review_lines, size=EMBEDDING_DIM, window=WINDOW_SIZE, workers=4, min_count=1 )\n",
        "words = list(model.wv.vocab)\n",
        "print(\"Vocabulary size (mängden ord): \", len(words))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size (mängden ord):  88585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B62kWPnlePPv"
      },
      "source": [
        "###Testa liknande ord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQW-_1l3c6h9"
      },
      "source": [
        "Vi kan nu köra några exempel på liknande ord, här tar vi ut top 3 liknande orden för några godtyckliga ord"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJV3paoIcP3A",
        "outputId": "2d075720-e494-4196-a856-9c23fcaf5ad0"
      },
      "source": [
        "print(\"Amazing resembles: \", model.wv.most_similar('amazing')[:3])\n",
        "print(\"Horrible resembles: \", model.wv.most_similar('horrible')[:3])\n",
        "print(\"Movie resembles: \", model.wv.most_similar('movie')[:3])\n",
        "print(\"Dog resembles: \", model.wv.most_similar('dog')[:3])\n",
        "print(\"Superhero resembles: \", model.wv.most_similar('superhero')[:3])\n",
        "\n",
        "print('\\n\\n')"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amazing resembles:  [('incredible', 0.8454157114028931), ('awesome', 0.8207459449768066), ('excellent', 0.7816787958145142)]\n",
            "Horrible resembles:  [('terrible', 0.9374001622200012), ('awful', 0.8611143827438354), ('laughable', 0.7919660806655884)]\n",
            "Movie resembles:  [('film', 0.9302455186843872), ('flick', 0.7232173085212708), ('show', 0.6845262050628662)]\n",
            "Dog resembles:  [('cat', 0.7753405570983887), ('rat', 0.7121865749359131), ('bottle', 0.711240291595459)]\n",
            "Superhero resembles:  [('gangster', 0.797494113445282), ('vampire', 0.7227295637130737), ('blaxploitation', 0.7127607464790344)]\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxt_Dk03eG5k"
      },
      "source": [
        "Vet inte vad jag tycker om att superhero är likt wannabe, demented och gangster..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPwUThdveSg9"
      },
      "source": [
        "Vi testar lite \"ord matematik\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuE6y2JleSCN",
        "outputId": "123226ab-c49c-467d-96c2-3ef2be0043f1"
      },
      "source": [
        "model.wv.most_similar_cosmul(positive=['woman','king'], negative=['man'])"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('jane', 0.9065161943435669),\n",
              " ('eyre', 0.8941454291343689),\n",
              " ('queen', 0.8744903802871704),\n",
              " ('austen', 0.8731036186218262),\n",
              " ('nancy', 0.8545281291007996),\n",
              " ('poppins', 0.8515877723693848),\n",
              " ('mary', 0.8512917757034302),\n",
              " ('alice', 0.84878009557724),\n",
              " ('bride', 0.8464763164520264),\n",
              " ('elizabeth', 0.8437730073928833)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEjnrDwwkXqE",
        "outputId": "db2be3c1-0f32-4189-9fc0-2935f7f69f17"
      },
      "source": [
        "model.wv.most_similar_cosmul(positive=['movie','film'], negative=['script'])"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('flick', 1.1458104848861694),\n",
              " ('documentary', 1.0899816751480103),\n",
              " ('cinema', 1.0817954540252686),\n",
              " ('picture', 1.045541763305664),\n",
              " ('movies', 1.035487413406372),\n",
              " ('show', 1.0194255113601685),\n",
              " ('program', 1.0079246759414673),\n",
              " ('films', 1.0069624185562134),\n",
              " ('episode', 0.986014723777771),\n",
              " ('series', 0.9820832014083862)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieG_ZmDJkgce",
        "outputId": "9419a06c-aea6-4ee2-9fac-b947da797b3c"
      },
      "source": [
        "model.wv.most_similar_cosmul(positive=['actor','woman'], negative=['man'])"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('actress', 1.0699996948242188),\n",
              " ('role', 0.8864448070526123),\n",
              " ('ms', 0.8801533579826355),\n",
              " ('accent', 0.874535858631134),\n",
              " ('winslett', 0.8656671643257141),\n",
              " ('performance', 0.8636323809623718),\n",
              " ('singer', 0.8610719442367554),\n",
              " ('performer', 0.8485500812530518),\n",
              " ('comedienne', 0.8470349907875061),\n",
              " ('dancer', 0.84434574842453)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwiJxuUCkrCD"
      },
      "source": [
        "Väldigt intressant att se hur modellen har placerat ord nära varandra. I vissa fall känns det väldigt självklart som att \"amazing\" liknar \"incredible\" men ibland blir det konstigt som att superhero liknar gangster. Samma sak uppstår vid beräkning av vektorerna, woman + king - man = jane. queen hamnar längre ner på listan men det finns i alla fall med. Dessa associationer beror mycket på hur stort window man ger modellen, kontexten blir helt annorlunda. Just för detta dataset är det även såklart smått begränsat till film termer. I alla fall om man vill få de bästa resultaten."
      ]
    }
  ]
}